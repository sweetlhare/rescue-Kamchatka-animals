{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = {\n",
    "    'Медведь': 0, \n",
    "    'Олень': 1, \n",
    "    'Рысь': 2, \n",
    "    'Лиса': 3,\n",
    "    'Тигр': 4,\n",
    "    'Леопард': 5,\n",
    "    'Ласка': 6,\n",
    "    'Волк': 7,\n",
    "    'Орёл': 8,\n",
    "    'Кабан': 9,\n",
    "    'Сайгак': 10,\n",
    "    'Белка': 11,\n",
    "    'Енот': 12,\n",
    "    'Человек': 13\n",
    "}\n",
    "\n",
    "# Человеков\n",
    "# Волки, кабаны\n",
    "# Барсуки\n",
    "# Хз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Камчатские данные + Other из Самары"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_data = pd.read_csv('boxed_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob('Распределённые животные/*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_data = pd.DataFrame()\n",
    "hand_data['path'] = glob('Распределённые животные/*/*')\n",
    "hand_data['file'] = [x.split('/')[-1] for x in glob('Распределённые животные/*/*')]\n",
    "hand_data['type'] = [x.split('/')[-2] for x in glob('Распределённые животные/*/*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(hand_data, box_data[['file', 'xmin', 'ymin', 'xmax', 'ymax']],\n",
    "                on=['file'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.type != 'Плохо определяются'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.file.nunique() == data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 867/867 [00:56<00:00, 15.30it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_width(path):\n",
    "    image = cv2.imread(path)\n",
    "    return image.shape[1]\n",
    "\n",
    "def get_height(path):\n",
    "    image = cv2.imread(path)\n",
    "    return image.shape[0]\n",
    "\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "for path in tqdm(data.path):\n",
    "    widths.append(get_width(path))\n",
    "    heights.append(get_height(path))\n",
    "    \n",
    "data['width'] = widths\n",
    "data['height'] = heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>file</th>\n",
       "      <th>type</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Распределённые животные/Медведь/209_IMG_0139_...</td>\n",
       "      <td>209_IMG_0139_S08.jpg</td>\n",
       "      <td>Медведь</td>\n",
       "      <td>857.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Распределённые животные/Медведь/220_IMG_1865_...</td>\n",
       "      <td>220_IMG_1865_S07.jpg</td>\n",
       "      <td>Медведь</td>\n",
       "      <td>156.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>2048</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Распределённые животные/Медведь/50_D1456528_S...</td>\n",
       "      <td>50_D1456528_S07.jpg</td>\n",
       "      <td>Медведь</td>\n",
       "      <td>30.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>2048</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Распределённые животные/Медведь/24_IMAG0472_S...</td>\n",
       "      <td>24_IMAG0472_S08.jpg</td>\n",
       "      <td>Медведь</td>\n",
       "      <td>0.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>2560</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Распределённые животные/Медведь/212_IMAG1942_...</td>\n",
       "      <td>212_IMAG1942_S08.jpg</td>\n",
       "      <td>Медведь</td>\n",
       "      <td>88.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>2560</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path                  file  \\\n",
       "0  Распределённые животные/Медведь/209_IMG_0139_...  209_IMG_0139_S08.jpg   \n",
       "1  Распределённые животные/Медведь/220_IMG_1865_...  220_IMG_1865_S07.jpg   \n",
       "2  Распределённые животные/Медведь/50_D1456528_S...   50_D1456528_S07.jpg   \n",
       "3  Распределённые животные/Медведь/24_IMAG0472_S...   24_IMAG0472_S08.jpg   \n",
       "4  Распределённые животные/Медведь/212_IMAG1942_...  212_IMAG1942_S08.jpg   \n",
       "\n",
       "      type   xmin   ymin    xmax    ymax  width  height  \n",
       "0  Медведь  857.0  367.0  1908.0  1027.0   1920    1080  \n",
       "1  Медведь  156.0  416.0  1572.0  1254.0   2048    1536  \n",
       "2  Медведь   30.0  390.0   855.0   922.0   2048    1536  \n",
       "3  Медведь    0.0  591.0   755.0  1225.0   2560    1920  \n",
       "4  Медведь   88.0  707.0  1029.0  1728.0   2560    1920  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['x_c'] = ( ((data['xmax'] + data['xmin']) / 2) / data['width'] ).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "data['y_c'] = ( ((data['ymax'] + data['ymin']) / 2) / data['height']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "data['width_box'] = ((data['xmax'] - data['xmin']) / data['width']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "data['height_box'] = ((data['ymax'] + data['ymin']) / data['height']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "data['yolo'] = data.apply(lambda x: str(TARGETS[x[2]]) + ' ' \n",
    "                          + ' '.join([str(round(s, 4)) for s in x[-4:]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>file</th>\n",
       "      <th>type</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>x_c</th>\n",
       "      <th>y_c</th>\n",
       "      <th>width_box</th>\n",
       "      <th>height_box</th>\n",
       "      <th>yolo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Распределённые животные/Медведь/209_IMG_0139_...</td>\n",
       "      <td>209_IMG_0139_S08.jpg</td>\n",
       "      <td>Медведь</td>\n",
       "      <td>857.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.720052</td>\n",
       "      <td>0.645370</td>\n",
       "      <td>0.547396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0 0.7201 0.6454 0.5474 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Распределённые животные/Медведь/220_IMG_1865_...</td>\n",
       "      <td>220_IMG_1865_S07.jpg</td>\n",
       "      <td>Медведь</td>\n",
       "      <td>156.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>2048</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>0.691406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0 0.4219 0.5436 0.6914 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Распределённые животные/Медведь/50_D1456528_S...</td>\n",
       "      <td>50_D1456528_S07.jpg</td>\n",
       "      <td>Медведь</td>\n",
       "      <td>30.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>2048</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.216064</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.402832</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0 0.2161 0.4271 0.4028 0.8542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Распределённые животные/Медведь/24_IMAG0472_S...</td>\n",
       "      <td>24_IMAG0472_S08.jpg</td>\n",
       "      <td>Медведь</td>\n",
       "      <td>0.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>2560</td>\n",
       "      <td>1920</td>\n",
       "      <td>0.147461</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>0.294922</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0 0.1475 0.4729 0.2949 0.9458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Распределённые животные/Медведь/212_IMAG1942_...</td>\n",
       "      <td>212_IMAG1942_S08.jpg</td>\n",
       "      <td>Медведь</td>\n",
       "      <td>88.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>2560</td>\n",
       "      <td>1920</td>\n",
       "      <td>0.218164</td>\n",
       "      <td>0.634115</td>\n",
       "      <td>0.367578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0 0.2182 0.6341 0.3676 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path                  file  \\\n",
       "0  Распределённые животные/Медведь/209_IMG_0139_...  209_IMG_0139_S08.jpg   \n",
       "1  Распределённые животные/Медведь/220_IMG_1865_...  220_IMG_1865_S07.jpg   \n",
       "2  Распределённые животные/Медведь/50_D1456528_S...   50_D1456528_S07.jpg   \n",
       "3  Распределённые животные/Медведь/24_IMAG0472_S...   24_IMAG0472_S08.jpg   \n",
       "4  Распределённые животные/Медведь/212_IMAG1942_...  212_IMAG1942_S08.jpg   \n",
       "\n",
       "      type   xmin   ymin    xmax    ymax  width  height       x_c       y_c  \\\n",
       "0  Медведь  857.0  367.0  1908.0  1027.0   1920    1080  0.720052  0.645370   \n",
       "1  Медведь  156.0  416.0  1572.0  1254.0   2048    1536  0.421875  0.543620   \n",
       "2  Медведь   30.0  390.0   855.0   922.0   2048    1536  0.216064  0.427083   \n",
       "3  Медведь    0.0  591.0   755.0  1225.0   2560    1920  0.147461  0.472917   \n",
       "4  Медведь   88.0  707.0  1029.0  1728.0   2560    1920  0.218164  0.634115   \n",
       "\n",
       "   width_box  height_box                           yolo  \n",
       "0   0.547396    1.000000     0 0.7201 0.6454 0.5474 1.0  \n",
       "1   0.691406    1.000000     0 0.4219 0.5436 0.6914 1.0  \n",
       "2   0.402832    0.854167  0 0.2161 0.4271 0.4028 0.8542  \n",
       "3   0.294922    0.945833  0 0.1475 0.4729 0.2949 0.9458  \n",
       "4   0.367578    1.000000     0 0.2182 0.6341 0.3676 1.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Тигры и леопарды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3537/3537 [04:04<00:00, 14.49it/s]\n",
      "100%|███████████████████████████████████████| 3517/3517 [03:43<00:00, 15.71it/s]\n"
     ]
    }
   ],
   "source": [
    "tiger_train = pd.read_csv('data/Tiger/objects.csv')\n",
    "leo_train = pd.read_csv('data/Leopard/objects.csv')\n",
    "\n",
    "tiger_train['path'] = tiger_train.id.apply(lambda x: 'data/Tiger/'+x)\n",
    "leo_train['path'] = leo_train.id.apply(lambda x: 'data/Leopard/'+x)\n",
    "\n",
    "# –––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––\n",
    "\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "for path in tqdm(tiger_train.path):\n",
    "    widths.append(get_width(path))\n",
    "    heights.append(get_height(path))\n",
    "    \n",
    "tiger_train['width'] = widths\n",
    "tiger_train['height'] = heights\n",
    "\n",
    "# –––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––\n",
    "\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "for path in tqdm(leo_train.path):\n",
    "    widths.append(get_width(path))\n",
    "    heights.append(get_height(path))\n",
    "    \n",
    "leo_train['width'] = widths\n",
    "leo_train['height'] = heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbox - xmin, ymin, xmax, ymax\n",
    "# yolo - x_c, y_c, width, height\n",
    "\n",
    "# center_x = ( (xmax + xmin) / 2) / width\n",
    "# center_y = ( (ymax + ymin) / 2) / height\n",
    "# width = (xmax - xmin) / width\n",
    "# height = (ymax - ymin) / height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiger_train['x_c'] = tiger_train.bbox.apply(lambda x: ( (float(x.split(' ')[2]) + float(x.split(' ')[0])) / 2 ) )\n",
    "tiger_train['x_c'] = (tiger_train['x_c'] / tiger_train['width']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "tiger_train['y_c'] = tiger_train.bbox.apply(lambda x: ( (float(x.split(' ')[3]) + float(x.split(' ')[1])) / 2 ) )\n",
    "tiger_train['y_c'] = (tiger_train['y_c'] / tiger_train['height']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "tiger_train['width_box'] = tiger_train.bbox.apply( lambda x: (float(x.split(' ')[2]) - float(x.split(' ')[0])) )\n",
    "tiger_train['width_box'] = (tiger_train['width_box'] / tiger_train['width']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "tiger_train['height_box'] = tiger_train.bbox.apply(lambda x: (float(x.split(' ')[3]) - float(x.split(' ')[1])) )\n",
    "tiger_train['height_box'] = (tiger_train['height_box'] / tiger_train['height']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "tiger_train['yolo'] = tiger_train.apply(lambda x: '{} '.format(TARGETS['Тигр']) + \n",
    "                                        ' '.join([str(round(s, 4)) for s in x[-4:]]), axis=1)\n",
    "\n",
    "# –––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––\n",
    "\n",
    "leo_train['x_c'] = leo_train.bbox.apply(lambda x: ( (float(x.split(' ')[2]) + float(x.split(' ')[0])) / 2 ) )\n",
    "leo_train['x_c'] = (leo_train['x_c'] / leo_train['width']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "leo_train['y_c'] = leo_train.bbox.apply(lambda x: ( (float(x.split(' ')[3]) + float(x.split(' ')[1])) / 2 ) )\n",
    "leo_train['y_c'] = (leo_train['y_c'] / leo_train['height']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "leo_train['width_box'] = leo_train.bbox.apply( lambda x: (float(x.split(' ')[2]) - float(x.split(' ')[0])) )\n",
    "leo_train['width_box'] = (leo_train['width_box'] / leo_train['width']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "leo_train['height_box'] = leo_train.bbox.apply(lambda x: (float(x.split(' ')[3]) - float(x.split(' ')[1])) )\n",
    "leo_train['height_box'] = (leo_train['height_box'] / leo_train['height']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "leo_train['yolo'] = leo_train.apply(lambda x: '{} '.format(TARGETS['Леопард']) + \n",
    "                                    ' '.join([str(round(s, 4)) for s in x[-4:]]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Формат йоло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>yolo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209_IMG_0139_S08.jpg</td>\n",
       "      <td>0 0.7201 0.6454 0.5474 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220_IMG_1865_S07.jpg</td>\n",
       "      <td>0 0.4219 0.5436 0.6914 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50_D1456528_S07.jpg</td>\n",
       "      <td>0 0.2161 0.4271 0.4028 0.8542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24_IMAG0472_S08.jpg</td>\n",
       "      <td>0 0.1475 0.4729 0.2949 0.9458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212_IMAG1942_S08.jpg</td>\n",
       "      <td>0 0.2182 0.6341 0.3676 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                           yolo\n",
       "0  209_IMG_0139_S08.jpg     0 0.7201 0.6454 0.5474 1.0\n",
       "1  220_IMG_1865_S07.jpg     0 0.4219 0.5436 0.6914 1.0\n",
       "2   50_D1456528_S07.jpg  0 0.2161 0.4271 0.4028 0.8542\n",
       "3   24_IMAG0472_S08.jpg  0 0.1475 0.4729 0.2949 0.9458\n",
       "4  212_IMAG1942_S08.jpg     0 0.2182 0.6341 0.3676 1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['file', 'yolo']].rename(columns={'file': 'id'}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>yolo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01020010_S02.jpg</td>\n",
       "      <td>5 0.5666 0.5382 0.3869 0.2594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212_IMG_0841_S02.jpg</td>\n",
       "      <td>5 0.543 0.7279 0.5449 0.5052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212_IMG_0840_S02.jpg</td>\n",
       "      <td>5 0.7336 0.6895 0.4937 0.4362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212_IMG_0839_S02.jpg</td>\n",
       "      <td>5 0.8469 0.6826 0.3032 0.4095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212_IMG_0838_S02.jpg</td>\n",
       "      <td>5 0.9446 0.6693 0.1079 0.3451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                           yolo\n",
       "0      01020010_S02.jpg  5 0.5666 0.5382 0.3869 0.2594\n",
       "1  212_IMG_0841_S02.jpg   5 0.543 0.7279 0.5449 0.5052\n",
       "2  212_IMG_0840_S02.jpg  5 0.7336 0.6895 0.4937 0.4362\n",
       "3  212_IMG_0839_S02.jpg  5 0.8469 0.6826 0.3032 0.4095\n",
       "4  212_IMG_0838_S02.jpg  5 0.9446 0.6693 0.1079 0.3451"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leo_train[['id', 'yolo']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>yolo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001_1.jpg</td>\n",
       "      <td>4 0.4392 0.4915 0.7339 0.4544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_758.jpg</td>\n",
       "      <td>4 0.6543 0.5404 0.5957 0.3984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_76.jpg</td>\n",
       "      <td>4 0.7946 0.6256 0.4078 0.5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002_761.jpg</td>\n",
       "      <td>4 0.1584 0.5202 0.3159 0.2826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002_762.jpg</td>\n",
       "      <td>4 0.2786 0.5075 0.4224 0.2806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                           yolo\n",
       "0    001_1.jpg  4 0.4392 0.4915 0.7339 0.4544\n",
       "1  002_758.jpg  4 0.6543 0.5404 0.5957 0.3984\n",
       "2   002_76.jpg  4 0.7946 0.6256 0.4078 0.5568\n",
       "3  002_761.jpg  4 0.1584 0.5202 0.3159 0.2826\n",
       "4  002_762.jpg  4 0.2786 0.5075 0.4224 0.2806"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiger_train[['id', 'yolo']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.concat([\n",
    "    data.rename(columns={'file': 'id', 'type': 'class'})[['path', 'id', 'yolo', 'class']], \n",
    "    leo_train[['path', 'id', 'yolo', 'class']].sample(500), \n",
    "    tiger_train[['path', 'id', 'yolo', 'class']].sample(500)\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all, val_all = train_test_split(data_all, test_size=0.15, stratify=data_all['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1584/1584 [02:15<00:00, 11.69it/s]\n"
     ]
    }
   ],
   "source": [
    "for image_file in tqdm(train_all.id.unique()):\n",
    "    \n",
    "    temp_ann = train_all[train_all.id == image_file]\n",
    "    image = cv2.imread(temp_ann.path.iloc[0])\n",
    "    \n",
    "    s_ann = ''\n",
    "    \n",
    "    for i, val in temp_ann.iterrows():\n",
    "        \n",
    "        s_ann += val['yolo']\n",
    "        if i != temp_ann.shape[0] - 1:\n",
    "            s_ann += '\\n'\n",
    "    \n",
    "    label_file = 'yolo_data/train/labels/'+image_file[:-4]+'.txt'\n",
    "    image_file = 'yolo_data/train/images/'+image_file\n",
    "    \n",
    "    with open(label_file, 'w') as f:\n",
    "        f.write(s_ann)\n",
    "    \n",
    "    cv2.imwrite(image_file, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 281/281 [00:25<00:00, 11.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for image_file in tqdm(val_all.id.unique()):\n",
    "    \n",
    "    temp_ann = val_all[val_all.id == image_file]\n",
    "    image = cv2.imread(temp_ann.path.iloc[0])\n",
    "    \n",
    "    s_ann = ''\n",
    "    \n",
    "    for i, val in temp_ann.iterrows():\n",
    "        \n",
    "        s_ann += val['yolo']\n",
    "        if i != temp_ann.shape[0] - 1:\n",
    "            s_ann += '\\n'\n",
    "    \n",
    "    label_file = 'yolo_data/val/labels/'+image_file[:-4]+'.txt'\n",
    "    image_file = 'yolo_data/val/images/'+image_file\n",
    "    \n",
    "    with open(label_file, 'w') as f:\n",
    "        f.write(s_ann)\n",
    "    \n",
    "    cv2.imwrite(image_file, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дополнение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = {\n",
    "    'Медведь': 0, \n",
    "    'Олень': 1, \n",
    "    'Рысь': 2, \n",
    "    'Лиса': 3,\n",
    "    'Тигр': 4,\n",
    "    'Леопард': 5,\n",
    "    'Волк': 6,\n",
    "    'Орёл': 7,\n",
    "    'Кабан': 8,\n",
    "    'Сайгак': 9,\n",
    "    'Белка': 10,\n",
    "    'Енот': 11,\n",
    "    'Человек': 12,\n",
    "    'Ласка': 13\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('new_data/for_yolo/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame()\n",
    "new_data['path'] = files\n",
    "new_data['id'] = [x.split('/')[-1] for x in files]\n",
    "new_data['class'] = [x.split('/')[-2] for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1289, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/neironeiro/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2021-12-4 torch 1.9.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1289it [03:11,  6.74it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, path in tqdm(enumerate(new_data.path)):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "        pred = model(image).pandas().xyxy[0].sort_values('confidence', ascending=False)\n",
    "            \n",
    "        new_data.loc[i, 'xmin'] = int(pred.xmin.iloc[0])\n",
    "        new_data.loc[i, 'ymin'] = int(pred.ymin.iloc[0])\n",
    "        new_data.loc[i, 'xmax'] = int(pred.xmax.iloc[0])\n",
    "        new_data.loc[i, 'ymax'] = int(pred.ymax.iloc[0])\n",
    "        \n",
    "        new_data.loc[i, 'animal'] = pred.name.iloc[0]\n",
    "            \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['box_square'] = (new_data.xmax - new_data.xmin) * (new_data.ymax - new_data.ymin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bear', 'cat', 'cow', 'dog', nan, 'horse', 'sheep', 'giraffe', 'car', 'sports ball', 'bird', 'elephant', 'person', 'frisbee', 'zebra', 'surfboard', 'bench', 'fire hydrant'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.animal.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_processed = new_data[(new_data.animal.isin(['bird', 'bear', 'dog', 'cat', 'sheep', 'horse', 'cow', \n",
    "                                                     'giraffe', 'bird', 'elephant', 'person', 'zebra']))\n",
    "                              &(new_data.box_square > 0.08*1920*1080)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Белка', 'Волк', 'Енот', 'Кабан', 'Ласка', 'Лиса', 'Медведь', 'Олень', 'Орёл', 'Рысь', 'Сайгак', 'Человек'], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(new_data_processed['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 9)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_processed[new_data_processed['class'] == 'Ласка'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data_processed = new_data_processed[new_data_processed['class'] != 'Ласка']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Сайгак'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_processed['class'].unique()[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Орёл'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_processed['class'].unique()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "saigak = new_data_processed['class'].unique()[8]\n",
    "new_data_processed.loc[new_data_processed['class'] == saigak, 'class'] = 'Сайгак'\n",
    "\n",
    "orel = new_data_processed['class'].unique()[10]\n",
    "new_data_processed.loc[new_data_processed['class'] == orel, 'class'] = 'Орёл'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## В йоло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_width(path):\n",
    "#     image = cv2.imread(path)\n",
    "#     return image.shape[1]\n",
    "\n",
    "# def get_height(path):\n",
    "#     image = cv2.imread(path)\n",
    "#     return image.shape[0]\n",
    "\n",
    "# widths = []\n",
    "# heights = []\n",
    "\n",
    "# for path in tqdm(new_data_processed.path):\n",
    "    # widths.append(get_width(path))\n",
    "    # heights.append(get_height(path))\n",
    "    \n",
    "new_data_processed['width'] = widths\n",
    "new_data_processed['height'] = heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_processed['x_c'] = ( ((new_data_processed['xmax'] + new_data_processed['xmin']) / 2) / new_data_processed['width'] ).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "new_data_processed['y_c'] = ( ((new_data_processed['ymax'] + new_data_processed['ymin']) / 2) / new_data_processed['height']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "new_data_processed['width_box'] = ((new_data_processed['xmax'] - new_data_processed['xmin']) / new_data_processed['width']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "new_data_processed['height_box'] = ((new_data_processed['ymax'] + new_data_processed['ymin']) / new_data_processed['height']).apply(lambda x: max(0, min(1, x)))\n",
    "\n",
    "new_data_processed['yolo'] = new_data_processed.apply(lambda x: str(TARGETS[x[2]]) + ' ' + ' '.join([str(round(s, 4)) for s in x[-4:]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proc, val_proc = train_test_split(new_data_processed, test_size=0.15, stratify=new_data_processed['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 976/976 [01:33<00:00, 10.42it/s]\n"
     ]
    }
   ],
   "source": [
    "for image_file in tqdm(train_proc.id.unique()):\n",
    "    \n",
    "    temp_ann = train_proc[train_proc.id == image_file]\n",
    "    image = cv2.imread(temp_ann.path.iloc[0])\n",
    "    \n",
    "    s_ann = ''\n",
    "    \n",
    "    for i, val in temp_ann.iterrows():\n",
    "        \n",
    "        s_ann += val['yolo']\n",
    "        if i != temp_ann.shape[0] - 1:\n",
    "            s_ann += '\\n'\n",
    "    \n",
    "    label_file = 'yolo_data/train/labels/'+image_file[:-4]+'.txt'\n",
    "    image_file = 'yolo_data/train/images/'+image_file\n",
    "    \n",
    "    with open(label_file, 'w') as f:\n",
    "        f.write(s_ann)\n",
    "    \n",
    "    cv2.imwrite(image_file, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:16<00:00, 10.35it/s]\n"
     ]
    }
   ],
   "source": [
    "for image_file in tqdm(val_proc.id.unique()):\n",
    "    \n",
    "    temp_ann = val_proc[val_proc.id == image_file]\n",
    "    image = cv2.imread(temp_ann.path.iloc[0])\n",
    "    \n",
    "    s_ann = ''\n",
    "    \n",
    "    for i, val in temp_ann.iterrows():\n",
    "        \n",
    "        s_ann += val['yolo']\n",
    "        if i != temp_ann.shape[0] - 1:\n",
    "            s_ann += '\\n'\n",
    "    \n",
    "    label_file = 'yolo_data/val/labels/'+image_file[:-4]+'.txt'\n",
    "    image_file = 'yolo_data/val/images/'+image_file\n",
    "    \n",
    "    with open(label_file, 'w') as f:\n",
    "        f.write(s_ann)\n",
    "    \n",
    "    cv2.imwrite(image_file, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Обучение YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = {\n",
    "    'Медведь': 0, \n",
    "    'Олень': 1, \n",
    "    'Рысь': 2, \n",
    "    'Лиса': 3,\n",
    "    'Тигр': 4,\n",
    "    'Леопард': 5,\n",
    "    'Волк': 6,\n",
    "    'Орёл': 7,\n",
    "    'Кабан': 8,\n",
    "    'Сайгак': 9,\n",
    "    'Белка': 10,\n",
    "    'Енот': 11,\n",
    "    'Человек': 12,\n",
    "    'Ласка': 13\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = \"yolov5/data/animal.yaml\"\n",
    "train_images_dir = os.path.join('..', 'yolo_data/train', 'images')\n",
    "val_images_dir = os.path.join('..', 'yolo_data/val', 'images')\n",
    "\n",
    "names_str = ''\n",
    "for item in list(TARGETS.keys()):\n",
    "    names_str = names_str + \", \\'%s\\'\"%item\n",
    "names_str = \"names: [\"+names_str[1:]+\"]\"\n",
    "\n",
    "with open(yaml_file, \"w\") as wobj:\n",
    "    wobj.write(\"train: %s\\n\"%train_images_dir)\n",
    "    wobj.write(\"val: %s\\n\"%val_images_dir)\n",
    "    wobj.write(\"nc: %d\\n\"%len(list(TARGETS.keys())))\n",
    "    wobj.write(names_str+\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=../yolov5/data/animal.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=30, batch_size=8, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 2 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.0-122-gd885799 torch 1.9.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Overriding model.yaml nc=80 with nc=14\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     51243  models.yolo.Detect                      [14, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 270 layers, 7057387 parameters, 7057387 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../yolo_data/train/labels' images and labels...1971 found, 14 m\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../yolo_data/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../yolo_data/val/labels' images and labels...556 found, 4 missing\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../yolo_data/val/labels.cache\n",
      "Plotting labels to runs/train/exp5/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.50 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp5\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/29        0G   0.07649   0.02286   0.05674         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.801      0.164      0.159     0.0796\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/29        0G   0.05269    0.0182   0.03693         3       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.811      0.286      0.265      0.139\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/29        0G   0.05169     0.017   0.02822         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556        0.9      0.259      0.308       0.17\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/29        0G   0.05069    0.0174    0.0278         3       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.757      0.288       0.28      0.162\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/29        0G   0.04807   0.01771   0.02582         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.904      0.274      0.328      0.187\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/29        0G   0.04467   0.01723   0.02325         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.782      0.346      0.339      0.219\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/29        0G   0.04138   0.01723     0.024         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.729      0.388       0.36      0.222\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/29        0G   0.04089   0.01635    0.0204         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.859       0.39      0.404      0.258\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/29        0G    0.0394   0.01646   0.01911         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.893       0.39      0.434      0.279\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/29        0G   0.03621   0.01575   0.01897         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.924      0.404      0.461      0.315\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/29        0G   0.03483   0.01584   0.01763         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.869      0.479      0.484      0.334\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/29        0G   0.03375   0.01537   0.01661         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556       0.83      0.464      0.484      0.348\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/29        0G    0.0332   0.01538   0.01686         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.706      0.519      0.491      0.353\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/29        0G   0.03306   0.01511    0.0153         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.931       0.47       0.51       0.38\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/29        0G   0.03221   0.01491   0.01437         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.924      0.478      0.509      0.373\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/29        0G   0.03027   0.01452   0.01467         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.762      0.572      0.526      0.403\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/29        0G   0.02962   0.01426    0.0141         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556       0.93      0.481      0.517      0.402\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/29        0G   0.02838   0.01356   0.01246         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556       0.75      0.607      0.571      0.435\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/29        0G   0.02823    0.0137   0.01296         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.895      0.548      0.558      0.444\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/29        0G   0.02703   0.01357   0.01162         0       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.768      0.575      0.592      0.487\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/29        0G   0.02606    0.0129   0.01148         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556       0.89      0.555      0.586      0.475\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/29        0G   0.02582   0.01328   0.01068         3       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.787      0.606      0.597      0.491\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/29        0G   0.02525   0.01323   0.01015         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556        0.8      0.623        0.6      0.484\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/29        0G   0.02529   0.01284  0.009809         3       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.795      0.623      0.614      0.509\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/29        0G   0.02348   0.01276  0.009722         3       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.714      0.716      0.655      0.551\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     25/29        0G    0.0233   0.01258  0.009219         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.751        0.7      0.667      0.564\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     26/29        0G   0.02305   0.01244  0.008954         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.806      0.658      0.658       0.55\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     27/29        0G   0.02274   0.01243  0.008724         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.835      0.646      0.671      0.567\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     28/29        0G   0.02262   0.01223  0.008327         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.759      0.725      0.689      0.583\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     29/29        0G   0.02207    0.0122  0.007917         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.739      0.741      0.674      0.583\n",
      "\n",
      "30 epochs completed in 3.798 hours.\n",
      "Optimizer stripped from runs/train/exp5/weights/last.pt, 14.4MB\n",
      "Optimizer stripped from runs/train/exp5/weights/best.pt, 14.4MB\n",
      "\n",
      "Validating runs/train/exp5/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7047883 parameters, 0 gradients, 15.9 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.759      0.726      0.689      0.583\n",
      "             Медведь        560        153      0.931          1      0.991      0.886\n",
      "               Олень        560         42      0.783      0.952      0.957      0.831\n",
      "                Рысь        560          6      0.998      0.667      0.813      0.798\n",
      "                Лиса        560        131      0.826      0.992      0.975      0.851\n",
      "                Тигр        560         75      0.872      0.987      0.973      0.799\n",
      "             Леопард        560         75      0.912       0.96      0.979      0.773\n",
      "                Волк        560         40      0.706          1      0.968      0.874\n",
      "                Орёл        560         10      0.292          1      0.813      0.612\n",
      "               Кабан        560         10      0.323          1      0.839      0.647\n",
      "              Сайгак        560          8      0.228      0.875      0.487      0.372\n",
      "               Белка        560          1          1          0          0          0\n",
      "                Енот        560          4          1          0      0.153      0.129\n",
      "             Человек        560          1          1          0     0.0117     0.0105\n",
      "Results saved to \u001b[1mruns/train/exp5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd yolov5 && python train.py --img 512 --batch 8 --epochs 30 --data ../yolov5/data/animal.yaml --weights yolov5s.pt\n",
    "\n",
    "# --weights ../yolov5/runs/train/exp4/weights/last.pt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../yolov5/runs/train/exp5/weights/last.pt, cfg=, data=../yolov5/data/animal.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=30, batch_size=8, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 2 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.0-122-gd885799 torch 1.9.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     51243  models.yolo.Detect                      [14, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 270 layers, 7057387 parameters, 7057387 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 349/349 items from ../yolov5/runs/train/exp5/weights/last.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../yolo_data/train/labels.cache' images and labels... 1971 foun\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../yolo_data/val/labels.cache' images and labels... 556 found, 4 \u001b[0m\n",
      "Plotting labels to runs/train/exp6/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.50 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp6\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/29        0G   0.02244   0.01184  0.008263         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.762      0.726      0.681      0.586\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/29        0G   0.02314   0.01186  0.008667         3       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.772      0.704      0.659      0.532\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/29        0G   0.02728   0.01257  0.009608         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.794      0.669      0.671      0.555\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/29        0G   0.03075   0.01305   0.01008         3       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.766      0.652      0.635      0.456\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/29        0G   0.03108   0.01369   0.01112         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.907      0.576      0.637      0.472\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/29        0G   0.03203   0.01396   0.01266         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.699      0.677      0.629      0.446\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/29        0G   0.03113   0.01425   0.01287         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.839      0.605      0.631       0.45\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/29        0G   0.03022   0.01357   0.01145         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.835      0.558      0.595      0.451\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/29        0G   0.03149   0.01428   0.01184         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.853      0.617      0.624      0.414\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/29        0G   0.02924   0.01386   0.01285         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.781      0.671      0.656      0.506\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/29        0G   0.02933   0.01414   0.01191         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.798      0.634      0.655      0.494\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/29        0G   0.02752    0.0136   0.01064         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.779      0.669      0.658      0.521\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/29        0G   0.02779   0.01331   0.01011         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.909      0.644      0.679      0.543\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/29        0G   0.02765   0.01321   0.01023         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.878      0.606      0.627      0.486\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/29        0G   0.02673   0.01337  0.009873         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.908      0.628      0.663      0.529\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/29        0G   0.02575   0.01281  0.009174         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.796      0.723      0.687      0.563\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/29        0G    0.0251    0.0125   0.00886         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.941      0.655      0.706      0.591\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/29        0G   0.02415   0.01217  0.008229         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.877      0.728      0.733      0.569\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/29        0G   0.02436   0.01238    0.0084         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.844      0.737       0.72      0.585\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/29        0G   0.02338   0.01227  0.008088         0       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.867       0.74      0.724      0.605\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/29        0G   0.02284   0.01166  0.008168         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.857      0.728      0.735      0.615\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/29        0G    0.0222   0.01199  0.006919         3       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.851      0.747      0.744      0.633\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/29        0G    0.0215   0.01195  0.006756         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.866      0.739      0.741      0.632\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/29        0G   0.02201   0.01164  0.007177         3       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556        0.9      0.739      0.755      0.649\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/29        0G   0.02078   0.01167  0.006716         3       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.892       0.73       0.75      0.635\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     25/29        0G   0.02062    0.0114  0.005981         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.899      0.761      0.764      0.668\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     26/29        0G   0.02044   0.01143  0.006041         4       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.919      0.738      0.755      0.656\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     27/29        0G   0.02004   0.01147  0.006509         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.927      0.737      0.763      0.669\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     28/29        0G   0.02033   0.01124  0.005972         1       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556      0.903      0.742      0.766      0.674\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     29/29        0G   0.02005   0.01121  0.005527         2       512: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556       0.92      0.745       0.77      0.674\n",
      "\n",
      "30 epochs completed in 3.790 hours.\n",
      "Optimizer stripped from runs/train/exp6/weights/last.pt, 14.4MB\n",
      "Optimizer stripped from runs/train/exp6/weights/best.pt, 14.4MB\n",
      "\n",
      "Validating runs/train/exp6/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7047883 parameters, 0 gradients, 15.9 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        560        556       0.92      0.745       0.77      0.674\n",
      "             Медведь        560        153      0.952          1      0.986      0.933\n",
      "               Олень        560         42      0.947          1      0.989      0.873\n",
      "                Рысь        560          6          1      0.733      0.909      0.813\n",
      "                Лиса        560        131      0.921      0.974       0.97      0.898\n",
      "                Тигр        560         75      0.963      0.987      0.979      0.818\n",
      "             Леопард        560         75      0.964      0.987      0.984      0.798\n",
      "                Волк        560         40      0.839          1      0.944      0.876\n",
      "                Орёл        560         10      0.553          1      0.921       0.77\n",
      "               Кабан        560         10      0.824          1      0.986      0.828\n",
      "              Сайгак        560          8          1          1      0.995      0.844\n",
      "               Белка        560          1          1          0          0          0\n",
      "                Енот        560          4          1          0     0.0969      0.093\n",
      "             Человек        560          1          1          0      0.249      0.224\n",
      "Results saved to \u001b[1mruns/train/exp6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd yolov5 && python train.py --img 512 --batch 8 --epochs 30 --data ../yolov5/data/animal.yaml --weights ../yolov5/runs/train/exp5/weights/last.pt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
